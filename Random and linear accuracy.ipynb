{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "646a0a17",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Error loading stopwords: <urlopen error [WinError 10060] A\n",
      "[nltk_data]     connection attempt failed because the connected party\n",
      "[nltk_data]     did not properly respond after a period of time, or\n",
      "[nltk_data]     established connection failed because connected host\n",
      "[nltk_data]     has failed to respond>\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "cannot import name '__version__' from 'sklearn' (unknown location)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 18\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnltk\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstem\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msnowball\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SnowballStemmer\n\u001b[0;32m     17\u001b[0m stemmer \u001b[38;5;241m=\u001b[39m SnowballStemmer(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124menglish\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfeature_extraction\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtext\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TfidfVectorizer\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m confusion_matrix,classification_report,accuracy_score\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\__init__.py:7\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;124;03mThe :mod:`sklearn.feature_extraction` module deals with feature extraction\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;124;03mfrom raw data. It currently includes methods to extract features from text and\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;124;03mimages.\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_dict_vectorizer\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DictVectorizer\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_hash\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m FeatureHasher\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mimage\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m img_to_graph, grid_to_graph\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\_dict_vectorizer.py:13\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msparse\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msp\u001b[39;00m\n\u001b[1;32m---> 13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BaseEstimator, TransformerMixin\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m check_array\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mDictVectorizer\u001b[39;00m(TransformerMixin, BaseEstimator):\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\base.py:15\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mre\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m __version__\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_config\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_config\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _IS_32BIT\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name '__version__' from 'sklearn' (unknown location)"
     ]
    }
   ],
   "source": [
    "import warnings \n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from wordcloud import WordCloud\n",
    "import re\n",
    "import pickle\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "stop = set(stopwords.words('english'))\n",
    "from nltk.tokenize import word_tokenize\n",
    "from textblob import TextBlob\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "stemmer = SnowballStemmer(\"english\")\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import confusion_matrix,classification_report,accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fd42ca69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\banga\\anaconda3\\lib\\site-packages (1.5.3)\n",
      "Requirement already satisfied: numpy>=1.20.3 in c:\\users\\banga\\anaconda3\\lib\\site-packages (from pandas) (1.23.5)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\banga\\anaconda3\\lib\\site-packages (from pandas) (2022.7)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\banga\\anaconda3\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\banga\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n",
      "Collecting seaborn\n",
      "  Downloading seaborn-0.12.2-py3-none-any.whl (293 kB)\n",
      "     ---------------------------------------- 0.0/293.3 kB ? eta -:--:--\n",
      "     - -------------------------------------- 10.2/293.3 kB ? eta -:--:--\n",
      "     - -------------------------------------- 10.2/293.3 kB ? eta -:--:--\n",
      "     - -------------------------------------- 10.2/293.3 kB ? eta -:--:--\n",
      "     - -------------------------------------- 10.2/293.3 kB ? eta -:--:--\n",
      "     --------- --------------------------- 71.7/293.3 kB 328.6 kB/s eta 0:00:01\n",
      "     ----------- ------------------------- 92.2/293.3 kB 327.7 kB/s eta 0:00:01\n",
      "     ------------- ---------------------- 112.6/293.3 kB 364.4 kB/s eta 0:00:01\n",
      "     --------------- -------------------- 122.9/293.3 kB 343.4 kB/s eta 0:00:01\n",
      "     --------------------- -------------- 174.1/293.3 kB 420.1 kB/s eta 0:00:01\n",
      "     ------------------------- ---------- 204.8/293.3 kB 461.0 kB/s eta 0:00:01\n",
      "     ---------------------------- ------- 235.5/293.3 kB 465.5 kB/s eta 0:00:01\n",
      "     --------------------------------- -- 276.5/293.3 kB 501.4 kB/s eta 0:00:01\n",
      "     -----------------------------------  286.7/293.3 kB 505.4 kB/s eta 0:00:01\n",
      "     ------------------------------------ 293.3/293.3 kB 477.3 kB/s eta 0:00:00\n",
      "Requirement already satisfied: numpy!=1.24.0,>=1.17 in c:\\users\\banga\\anaconda3\\lib\\site-packages (from seaborn) (1.23.5)\n",
      "Requirement already satisfied: matplotlib!=3.6.1,>=3.1 in c:\\users\\banga\\anaconda3\\lib\\site-packages (from seaborn) (3.7.0)\n",
      "Requirement already satisfied: pandas>=0.25 in c:\\users\\banga\\anaconda3\\lib\\site-packages (from seaborn) (1.5.3)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\banga\\anaconda3\\lib\\site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (3.0.9)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in c:\\users\\banga\\anaconda3\\lib\\site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (5.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\banga\\anaconda3\\lib\\site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (0.11.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\banga\\anaconda3\\lib\\site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (2.8.2)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\banga\\anaconda3\\lib\\site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (22.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\banga\\anaconda3\\lib\\site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (9.4.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\banga\\anaconda3\\lib\\site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (1.0.5)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\banga\\anaconda3\\lib\\site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (1.4.4)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\banga\\anaconda3\\lib\\site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (4.25.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\banga\\anaconda3\\lib\\site-packages (from pandas>=0.25->seaborn) (2022.7)\n",
      "Requirement already satisfied: zipp>=3.1.0 in c:\\users\\banga\\anaconda3\\lib\\site-packages (from importlib-resources>=3.2.0->matplotlib!=3.6.1,>=3.1->seaborn) (3.11.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\banga\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.1->seaborn) (1.16.0)\n",
      "Installing collected packages: seaborn\n",
      "Successfully installed seaborn-0.12.2\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas\n",
    "!pip install seaborn\n",
    "#import nltk\n",
    "#nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe21841f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('tripadvisor_hotel_reviews.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89b3fcd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f876dc49",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9435f394",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe091580",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "637d8c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(x = df['Rating'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d54d0c40",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_theme(style=\"white\", color_codes=True)\n",
    "sns.countplot(x = df['Rating'], palette=['pink', 'Aqua','coral','teal', 'lime']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d14048d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Word_count']= df['Review'].map(lambda x: len(x.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4c580ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa7f922a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(x = 'Rating', y='Word_count', data=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22458d9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lineplot(x='Rating', y='Word_count', data=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bbc350e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install textblob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6ec18cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install wordcloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ba0e4c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def polarity(x):\n",
    "    blob = TextBlob(x)\n",
    "    return blob.sentiment.polarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c038aa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def subjectivity(x):\n",
    "    blob = TextBlob(x)\n",
    "    return blob.sentiment.subjectivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de75eea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['polarity']= df['Review'].apply(polarity)\n",
    "df['Subjectivity']= df['Review'].apply(subjectivity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c38e3bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f26947b",
   "metadata": {},
   "outputs": [],
   "source": [
    "conditions = [\n",
    "    (df['polarity']>0),\n",
    "    (df['polarity']<0),\n",
    "    (df['polarity']==0)\n",
    "]\n",
    "values = ['Positive','Negative','Nuetral']\n",
    "df['polarity_new'] = np.select(conditions,values) #distribute "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "257cbb2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(df['polarity'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d67bb46",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(df['Subjectivity'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0ba484b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x='polarity_new',hue='Rating',data=df, palette=\"Set1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4366ff44",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(x='Rating',y='polarity', data=df, whis=2.5, fliersize= 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a2242ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(x='Rating',y='Subjectivity', data=df, whis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db941ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Review'] = df['Review'].apply(lambda x:' '.join([word for word in x.split() if word not in (stop)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b743f5e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21e9bb91",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Review_stemming'] = df['Review'].str.split()\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "df['Review_stemming'] = df['Review_stemming'].apply(lambda x: [stemmer.stem(y) for y in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8325737",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeb96cf9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "w_tokenizer = nltk.tokenize.WhitespaceTokenizer()\n",
    "lemmatizer = nltk.stem.WordNetLemmatizer()\n",
    "\n",
    "def lemmatize_text(text):\n",
    "    return [lemmatizer.lemmatize(w) for w in w_tokenizer.tokenize(text)]\n",
    "df['Review_lemmatize'] = df.Review.apply(lemmatize_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b5c6b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7d71e49",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_sentences(data,name):\n",
    "    data[name]=data[name].apply(lambda x:' '.join([i+' ' for i in x]))\n",
    "    data[name]=data[name].apply(lambda x:re.sub(r'\\s+', ' ', x, flags=re.I))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b411c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "make_sentences(df,'Review_stemming')\n",
    "make_sentences(df,'Review_lemmatize')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "557517de",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d513a175",
   "metadata": {},
   "outputs": [],
   "source": [
    "rev_stemming = \" \".join([review for review in df['Review_stemming']])\n",
    "rev_stemming[:2000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c20a5ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "rev_lmtz = \" \".join([review for review in df['Review_lemmatize']])\n",
    "rev_lmtz[:2000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2597d42",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,7))\n",
    "wc= WordCloud(max_words=200,height= 800, width=1000 ,background_color='black').generate(rev_stemming)\n",
    "plt.imshow(wc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41b65ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,7))\n",
    "wc= WordCloud(max_words=200,height= 800, width=1000 ,background_color='black').generate(rev_lmtz)\n",
    "plt.imshow(wc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebd840c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiment(review):\n",
    "    if review>=3:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "df['Sentiment']= df['Rating'].apply(sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18a90289",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69575a98",
   "metadata": {},
   "outputs": [],
   "source": [
    "X= df['Review_stemming']\n",
    "Y= df['Sentiment']\n",
    "\n",
    "X_train, X_test,y_train, y_test= train_test_split(X, Y, test_size=0.25, stratify=Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14f523a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf= TfidfVectorizer(max_features=10000, tokenizer= word_tokenize,ngram_range=(1,2) )\n",
    "X_train_tfidf= tfidf.fit_transform(X_train.values)\n",
    "X_test_tfidf= tfidf.transform(X_test.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a693e65d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(tfidf, open('tfidf.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57a6e9a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr= LogisticRegression()\n",
    "lr.fit(X_train_tfidf, y_train)\n",
    "y_pred_tfidf = lr.predict(X_test_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72b79198",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(lr, open('trip_review.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01a8eae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(confusion_matrix(y_test,y_pred_tfidf))\n",
    "print(accuracy_score(y_test,y_pred_tfidf))\n",
    "print(classification_report(y_test,y_pred_tfidf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3da28ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(n_estimators=20, random_state=0)\n",
    "clf.fit(X_train_tfidf,y_train)\n",
    "y_pred = clf.predict(X_test_tfidf)\n",
    "\n",
    "print(confusion_matrix(y_test,y_pred))  \n",
    "print(classification_report(y_test,y_pred))  \n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24ab8f1e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c19cc1ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tfidf = X_train_tfidf.todense()\n",
    "X_test_tfidf = X_test_tfidf.todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd1f45a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = pickle.load(open('trip_review.pkl','rb'))\n",
    "tfidf = pickle.load(open('tfidf.pkl','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60df042d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def review_predictor(text):\n",
    "    df =pd.DataFrame([[text]],columns=['Review'])\n",
    "    df['Review'] = df['Review'].apply(lambda x:' '.join([word for word in x.split() if word not in (stop)]))\n",
    "    df['Review'] = df['Review'].str.split()\n",
    "    df['Review'] = df['Review'].apply(lambda x: [stemmer.stem(y) for y in x])\n",
    "    df['Review'] = df['Review'].apply(lambda x:' '.join([i+' ' for i in x]))\n",
    "    df['Review'] = df['Review'].apply(lambda x:re.sub(r'\\s+', ' ', x, flags=re.I))\n",
    "    X = df['Review']\n",
    "    X = tfidf.transform(X)\n",
    "    X = model.predict(X)\n",
    "    X = X[0]\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f456916a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = input(\"Please enter a Review:\\n\")\n",
    "predict = review_predictor(test)\n",
    "if predict == 0:\n",
    "    print(\"Negative Review\")\n",
    "else:\n",
    "    print(\"Positive Review\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba23b5c9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
